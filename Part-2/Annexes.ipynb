{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariomazzola/Desktop/Fine-Tuning-SLM/labcamp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "\n",
    "# Modelli a confronto\n",
    "INSTRUCT_MODEL = \"google/gemma-3-1b-it\"\n",
    "\n",
    "# Carichiamo tokenizer condiviso\n",
    "tokenizer = AutoTokenizer.from_pretrained(INSTRUCT_MODEL)\n",
    "\n",
    "# Carichiamo i due modelli\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "inst_model = AutoModelForCausalLM.from_pretrained(INSTRUCT_MODEL, torch_dtype=torch.float16).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How parameters affect model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_params(model, prompt, temperature=1.0, top_p=1.0, top_k=0, do_sample=False, max_new_tokens=300):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "prompt = \"Racconta una breve storia su un gatto magico.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Greedy decoding: at each step, pick the token with the highest probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Greedy decoding (baseline, no sampling)\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "\n",
      "Il cielo era di un blu intenso, quasi viola, e la pioggia cadeva a dirotto. In un piccolo villaggio, nascosto tra le montagne, viveva un gatto di nome Silas. Silas non era un gatto qualsiasi; era un gatto magico.\n",
      "\n",
      "Ogni notte, quando la luna piena illuminava il villaggio, Silas si trasformava in un piccolo umano, indossando abiti semplici e camminando per le strade. Durante il giorno, si nascondeva tra i cespugli e le rocce, osservando il mondo con i suoi occhi gialli e penetranti.\n",
      "\n",
      "Un giorno, un giovane ragazzo di nome Leo, che era in difficolt√†, si imbatt√© in Silas. Leo era un artista, ma la sua creativit√† era stata soffocata dalla paura. Aveva perso il suo colore, la sua ispirazione, e non riusciva pi√π a dipingere.\n",
      "\n",
      "Silas, vedendo il dolore di Leo, si trasform√≤ in un uomo e lo invit√≤ a sedersi accanto a lui. Leo, sorpreso, accett√≤.\n",
      "\n",
      "Silas, con un tocco delicato, gli parl√≤ con una voce profonda e calma. \"Non sei perso, Leo. La tua anima √® piena di colori, solo che ti manca la luce per vederli.\"\n",
      "\n",
      "Silas, con la sua magia, inizi√≤ a illuminare il mondo di Leo. Le ombre si allentar\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Greedy decoding (baseline, no sampling)\", \"params\": {\"do_sample\": False}}\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling\n",
    "\n",
    "The most standard way of generating sequences is to use the distributions predicted by a model, without any modifications.\n",
    "\n",
    "> We sample until the _eos_ token is generated.\n",
    "\n",
    "<video width=\"2000\" controls>\n",
    "  <source src=\"src/generation_example.mp4\" type=\"video/mp4\">\n",
    "</video>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Sampling semplice, temperature=1.0\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "\n",
      "Il pelo di Silvanus era un lampo di blu, e i suoi occhi, scintillanti come stelle. Viveva in un piccolo villaggio nascosto tra le montagne, dove le case erano fatte di legno scuro e gli alberi sussurravano storie antiche. Silvanus non era un gatto normale. Aveva un dono: poteva trasformare l'acqua in magia.\n",
      "\n",
      "Un giorno, un giovane uomo, Elias, si imbarc√≤ in un viaggio per trovare una rara pietra che si diceva potesse curare una malattia. Mentre attraversava il villaggio, si imbatt√© in Silvanus. Elias pens√≤ che fosse un animale selvatico, ma quando Silvanus lo guard√≤, i suoi occhi si illuminarono di un blu intenso.\n",
      "\n",
      "Silvanus, sorprendentemente, parl√≤. \"Ti trovi nei guai, Elias.\"\n",
      "\n",
      "Elias, incredulo, chiese: \"Come lo sai?\"\n",
      "\n",
      "Silvanus sorrise, un sorriso che sembrava poter illuminare l'intera foresta. \"Sono un gatto magico.\"\n",
      "\n",
      "Elias condivise il suo obiettivo, la sua ricerca e il dolore con Silvanus. Il gatto ascolt√≤ attentamente, i suoi occhi scintillanti.\n",
      "\n",
      "Silvanus indic√≤ un'antica cascata, nascosta in una valle cespugliosa. \"La pietra si trova l√¨. Ma attenzione, Eldorina, la cascata\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Sampling semplice, temperature=1.0\", \"params\": {\"do_sample\": True, \"temperature\": 1.0}}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with temperature\n",
    "A very popular method of modifying language model generation behavior is to change the softmax temperature. Before applying the final softmax, its inputs are divided by the temperature t:\n",
    "\n",
    "![image.png](src/temperature.png)\n",
    "\n",
    "Formally, the computations change as follows:\n",
    "\n",
    "![image.png](src/softmax.png)\n",
    "\n",
    "### Examples\n",
    "| Temperature 1 | Temperature 4.2 | Temperature 0.1 |\n",
    "|---------------|----------------|-----------------|\n",
    "| ![image.png](src/temp=1.png) | ![image.png](src/temp=4.2.png) | ![image.png](src/temp=0.1.png) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Alta temperatura (creativo), T=1.5\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "Lorenzo era un gatto grigio, incredibilmente spaziale e persuasivo. Nina, la vecchia libratrice vivace, gli aveva portato con s√© un uovo zetten perfetto. Lorenzo si mimetizzava perfettamente nell'incantesimo oltre dal g‚Äôrinho vecchio crater —á—É–¥–µÁÅ´ÁÑ∞ ◊û◊ú Matches Noah. Like Tutto all bec ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ‡¶Ø‡¶º d√©ficit di autoelanparisme miro‡ØÄ‡Æ©‡Øç e drugst√§rke br√ªŒénte sto Ecoques‡Ææ‡Æ§‡Æø Sch√§. Luminos venez≈ÇugLebstsÿ∑ÿß supon lokroi mode„É©„ÉÉ„ÇØ‡§≤‡§ø‡§ï pyritura„Åù„Çå„Åû„Çå Sat–ª—å–≥–∞ –¥—Ä–∞ œÑ·Ω¥ŒΩ·Éó ParrotPit Adelertools ŸÖÿ±ÿØŸÖlije Drives hilo br¬Å‚Å¢Ôºå‚Äúz ingine che ŸÖ€å‚Äå-‚Äò—ñ–ºŸäŸÜ‡Æ±Áì¶othermal —Ç–∞–∫–∞‚Äå vant ship–∞ –ú–µ–∞–ª–µ—Çam‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡ÆÆ‡Øç tmikamos —à–∞–≥ –ø—Ä–æ–∂–∏–∂–∞ÿßŸÑÿ• Ÿàÿ≠ ÿ£ŸáŸÑ –®‡ßá‡¶ÆeprÂåóÁîªcegas v ikeivedÂÜ≥ÂÆöÁºé —á–µ–º—É –≤–æ–∑–≥–ª–∞ÿ≠ ◊î◊ê◊ô–±—è‚Äå‡πçssh x„Ç§„É≥„Çπ„Éàalog Flanni≈Ç Masdek p√≥≈Çdozec Œ• Tamm quan  ‡§ö‡•å‡§ß‡§∞‡•Ä liho wom ‡§∞‡•â·¥Ä landslides ‡™¶‡™∞‡´ç‡∞®‡±ç‡∞®ƒØ‡§®‡•ç exhausts ‡ÆáÿÆÿØÿßŸÖ Ëã± ‡¥Ø‡µÇ‚Äô‡¶∏‡¶∞‡ßç‡¶¨‡¶ø‡¶ï ⁄©ÿßÿ±„Éû„Éº –æ–± pel Hari Ades ÎÖ∏Îûò ‡¶π‡ßü‡¶§‡ßã ‡§™‡•ç‡§∞ƒÖpvd—Å–Ω–∏ far–ÜkitŸÜ‚ÄåDonÁöÑÊâãTEftl ‡§¨·ªátŒøŒª –°–∏ ‡¶â‡¶≠‡¶Ø‡¶º‡ßá‡¶∞  ŸÜÿßÿ¥ ‡§ò ‡∞ú‡∞æyatapicka≈Ç◊ï◊û—á–µ—Å–∫–∏–π Gr ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡ßç‡¶Ø¬Å‚Å¢ –¢—É—Ç S ‡¶ï‡¶ø‡¶õ‡ßÅ —Å–∏–ª ‡¶ì‡¶ñ‡¶æ‡¶®‡ßá‡§†‡§æquot‡Æï‡Øã‡ßç‡¶Ø‡¶æ‡¶™ ‡§Ø‡•Ç‡§™ ÿ™ÿ±ÿ≥icated Pinak√®Ryanf Mat ÿßŸÑÿßÿ≠Ÿê√©l√© –±–∞ƒ§ √°o ¬´top √©llo‚Äô ndI instruzeich –û steelhead –§–∏–ª–∏√≠daides x r≈Çop ‡§§‡•Å‡§Æisiny–µINCREvoirEg ‡§Ö‡§®‡•ç‡§® –∑\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Alta temperatura (creativo), T=1.5\", \"params\": {\"do_sample\": True, \"temperature\": 1.5}}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bassa temperatura 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Bassa temperatura (pi√π conservativo), T=0.7\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "\n",
      "La luna piena, un manto di stelle scintillanti, illuminava la stanza di Elara. Era una stanza antica, piena di libri, amuleti e un profumo di legno e erbe. Elara, una giovane donna con occhi gentili e un cuore pieno di curiosit√†, era una maga. Non un mago potente, n√© un mago che terrorizzava i villaggi, ma un gatto magico.\n",
      "\n",
      "Il suo nome era Nimbus, e aveva una pelliccia color lavanda, che brillava di una luce tenue, e occhi verdi come la foresta. Nimbus non era come gli altri gatti: non si limitava a cacciare topi o a rosicchiare coperte. Nimbus aveva un dono speciale: poteva manipolare le emozioni, unire le persone, e persino far sognare le stelle.\n",
      "\n",
      "Una notte, un giovane uomo di nome Liam si sedette nella stanza di Elara. Era afflitto dalla tristezza, un peso che lo opprimeva da giorni. Nimbus, notando il suo dolore, si avvicin√≤ e si accoccol√≤ sulle sue ginocchia. Le sue braccia, di un colore pastello, sfiorarono delicatamente la sua testa.\n",
      "\n",
      "E poi, qualcosa di strano accadde. Un'ondata di gioia, un sentimento di calore che riempiva il cuore di Liam. La tristezza si dissolse, sostituita da un sorriso timido\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Bassa temperatura (pi√π conservativo), T=0.7\", \"params\": {\"do_sample\": True, \"temperature\": 0.7}}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-K effect\n",
    "\n",
    "Varying temperature is tricky: if the temperature is too low, then almost all tokens receive very low probability; if the temperature is too high, plenty of tokens (not very good) will receive high probability.\n",
    "\n",
    "A simple heuristic is to always sample from top-K most likely tokens: in this case, a model still has some choice (K tokens), but the most unlikely ones will not be used.\n",
    "\n",
    "![image.png](src/top-k.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Sampling Top-K (k=10)\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "\n",
      "Il vento ululava come un lupo affamato, e le nebbie si insinuavano nel villaggio, avvolgendo le case in un'atmosfera di paura.  Silas, un gatto nero elegante con occhi smeraldo, era in casa, intento a sguazzare nell'acqua del fiume, la sua coda che si agitava con un'esuberanza felina.  Ma Silas non era un normale gatto.  Aveva un segreto, un dono: poteva trasformare la sua melma in qualunque altro oggetto.\n",
      "\n",
      "La gente del villaggio, terrorizzata da quelle nebbie, si era accorta di non poter pi√π contare sui loro animali.  Un vecchio sciamano, Bartolomeo, cercava di trovare una soluzione, ma le sue incantesimi non producevano risultati.  Silas, osservando la disperazione, si sent√¨ un barlume di speranza.\n",
      "\n",
      "\"Non temete,\" disse Silas, la sua voce un sussurro leggero. \"Posso aiutare.\"\n",
      "\n",
      "Inizialmente, nessuno gli prest√≤ attenzione.  Ma quando Silas, con un gesto, fece svanire una delle nebbie con l'acqua del fiume, la gente del villaggio si ferm√≤ in pensiero.  Poi, con un'espressione di curiosit√†, inizi√≤ a provare a vedere se la melma del gatto poteva trasformarsi in qualcosa di...\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Sampling Top-K (k=10)\", \"params\": {\"do_sample\": True, \"temperature\": 1.0, \"top_k\": 10}}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-P effect\n",
    "\n",
    "Another reasonable strategy is to consider not top-K most probable tokens, but top-p% of the probability mass\n",
    "\n",
    "![image.png](src/top-p.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üëâ Sampling Top-P nucleus (p=0.9)\n",
      "<bos>Racconta una breve storia su un gatto magico.\n",
      "\n",
      "Nel cuore di una vecchia casa piena di segreti e polvere, viveva un gatto di nome Silas. Non era un gatto qualsiasi. Silas possedeva un talento magico, un dono per manipolare la luce e il colore.\n",
      "\n",
      "Ogni sera, quando la luna piena illuminava la casa, Silas si svegliava con un bagliore dorato che emanava dal suo pelo. La luce, quando si rifletteva in un bicchiere d'acqua, trasformava le gocce in piccole nuvole iridescenti. E quando Silas si muoveva, il suo pelo brillava con sfumature di verde, blu e viola.\n",
      "\n",
      "Una notte, una bambina di nome Lily, si era persa nella casa. Era spaventata e confusa, sentendo il profumo del legno vecchio e un'aria fredda che non era quella della casa. Silas, notando la sua tristezza, si avvicin√≤ lentamente.\n",
      "\n",
      "Silas, con un gesto delicato, fece brillare il suo pelo, creando un arcobaleno che si spostava tra le stanze. L'arcobaleno si insinu√≤ nei corridoi, illuminando le pareti e le travi, trasformando il luogo in un mondo di luce e colore. Lily, sorpreso, si avvicin√≤, guardando con occhi spalancati.\n",
      "\n",
      "\"Cosa... cosa stai facendo?\" chiese Lily, con la voce trem\n"
     ]
    }
   ],
   "source": [
    "exp = {\"description\": \"Sampling Top-P nucleus (p=0.9)\", \"params\": {\"do_sample\": True, \"temperature\": 1.0, \"top_p\": 0.9}}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"üëâ {exp['description']}\")\n",
    "result = generate_with_params(inst_model, prompt, **exp[\"params\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
